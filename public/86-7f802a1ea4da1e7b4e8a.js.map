{"version":3,"file":"86-7f802a1ea4da1e7b4e8a.js","mappings":"yBAAA,SAASA,IAAQ,CAqMjB,SAASC,EAAYC,EAAMC,EAAYC,EAAWC,EAAWC,GAM3D,IALA,IAAIC,EAAe,EACfC,EAAeL,EAAWM,OAC1BC,EAAS,EACTC,EAAS,EAENJ,EAAeC,EAAcD,IAAgB,CAClD,IAAIK,EAAYT,EAAWI,GAE3B,GAAKK,EAAUC,SAuBb,GALAD,EAAUE,MAAQZ,EAAKa,KAAKV,EAAUW,MAAML,EAAQA,EAASC,EAAUK,QACvEN,GAAUC,EAAUK,MAIhBV,GAAgBJ,EAAWI,EAAe,GAAGW,MAAO,CACtD,IAAIC,EAAMhB,EAAWI,EAAe,GACpCJ,EAAWI,EAAe,GAAKJ,EAAWI,GAC1CJ,EAAWI,GAAgBY,CAC7B,MA3BsB,CACtB,IAAKP,EAAUM,OAASZ,EAAiB,CACvC,IAAIQ,EAAQV,EAAUY,MAAMN,EAAQA,EAASE,EAAUK,OACvDH,EAAQA,EAAMM,KAAI,SAAUN,EAAOO,GACjC,IAAIC,EAAWjB,EAAUM,EAASU,GAClC,OAAOC,EAASb,OAASK,EAAML,OAASa,EAAWR,CACrD,IACAF,EAAUE,MAAQZ,EAAKa,KAAKD,EAC9B,MACEF,EAAUE,MAAQZ,EAAKa,KAAKX,EAAUY,MAAMN,EAAQA,EAASE,EAAUK,QAGzEP,GAAUE,EAAUK,MAEfL,EAAUM,QACbP,GAAUC,EAAUK,MAExB,CAYF,CAKA,IAAIM,EAAgBpB,EAAWK,EAAe,GAO9C,OALIA,EAAe,GAAoC,iBAAxBe,EAAcT,QAAuBS,EAAcL,OAASK,EAAcV,UAAYX,EAAKsB,OAAO,GAAID,EAAcT,SACjJX,EAAWK,EAAe,GAAGM,OAASS,EAAcT,MACpDX,EAAWsB,OAGNtB,CACT,CAEA,SAASuB,EAAUC,GACjB,MAAO,CACLjB,OAAQiB,EAAKjB,OACbP,WAAYwB,EAAKxB,WAAWa,MAAM,GAEtC,CA7PAhB,EAAK4B,UAAY,CACf1B,KAAM,SAAcG,EAAWD,GAC7B,IAAIyB,EAAUC,UAAUrB,OAAS,QAAsBsB,IAAjBD,UAAU,GAAmBA,UAAU,GAAK,CAAC,EAC/EE,EAAWH,EAAQG,SAEA,mBAAZH,IACTG,EAAWH,EACXA,EAAU,CAAC,GAGbI,KAAKJ,QAAUA,EACf,IAAIK,EAAOD,KAEX,SAASE,EAAKrB,GACZ,OAAIkB,GACFI,YAAW,WACTJ,OAASD,EAAWjB,EACtB,GAAG,IACI,GAEAA,CAEX,CAGAT,EAAY4B,KAAKI,UAAUhC,GAC3BD,EAAY6B,KAAKI,UAAUjC,GAC3BC,EAAY4B,KAAKK,YAAYL,KAAKM,SAASlC,IAE3C,IAAImC,GADJpC,EAAY6B,KAAKK,YAAYL,KAAKM,SAASnC,KACpBK,OACnBgC,EAASpC,EAAUI,OACnBiC,EAAa,EACbC,EAAgBH,EAASC,EACzBG,EAAW,CAAC,CACdlC,QAAS,EACTP,WAAY,KAGVQ,EAASsB,KAAKY,cAAcD,EAAS,GAAIxC,EAAWC,EAAW,GAEnE,GAAIuC,EAAS,GAAGlC,OAAS,GAAK8B,GAAU7B,EAAS,GAAK8B,EAEpD,OAAON,EAAK,CAAC,CACXrB,MAAOmB,KAAKlB,KAAKX,GACjBa,MAAOb,EAAUK,UAKrB,SAASqC,IACP,IAAK,IAAIC,GAAgB,EAAIL,EAAYK,GAAgBL,EAAYK,GAAgB,EAAG,CACtF,IAAIC,OAAW,EAEXC,EAAUL,EAASG,EAAe,GAClCG,EAAaN,EAASG,EAAe,GACrCI,GAAWD,EAAaA,EAAWxC,OAAS,GAAKqC,EAEjDE,IAEFL,EAASG,EAAe,QAAKhB,GAG/B,IAAIqB,EAASH,GAAWA,EAAQvC,OAAS,EAAI8B,EACzCa,EAAYH,GAAc,GAAKC,GAAWA,EAAUV,EAExD,GAAKW,GAAWC,EAAhB,CAqBA,IAZKD,GAAUC,GAAaJ,EAAQvC,OAASwC,EAAWxC,QACtDsC,EAAWtB,EAAUwB,GACrBhB,EAAKoB,cAAcN,EAAS7C,gBAAY4B,GAAW,MAEnDiB,EAAWC,GAEFvC,SACTwB,EAAKoB,cAAcN,EAAS7C,YAAY,OAAM4B,IAGhDoB,EAAUjB,EAAKW,cAAcG,EAAU5C,EAAWC,EAAW0C,GAEzDC,EAAStC,OAAS,GAAK8B,GAAUW,EAAU,GAAKV,EAClD,OAAON,EAAKlC,EAAYiC,EAAMc,EAAS7C,WAAYC,EAAWC,EAAW6B,EAAK5B,kBAG9EsC,EAASG,GAAgBC,CArB3B,MAFEJ,EAASG,QAAgBhB,CAyB7B,CAEAW,GACF,CAKA,GAAIV,GACF,SAAUuB,IACRnB,YAAW,WAIT,GAAIM,EAAaC,EACf,OAAOX,IAGJc,KACHS,GAEJ,GAAG,EACJ,CAbD,QAeA,KAAOb,GAAcC,GAAe,CAClC,IAAIa,EAAMV,IAEV,GAAIU,EACF,OAAOA,CAEX,CAEJ,EACAF,cAAe,SAAuBnD,EAAYe,EAAOL,GACvD,IAAI4C,EAAOtD,EAAWA,EAAWM,OAAS,GAEtCgD,GAAQA,EAAKvC,QAAUA,GAASuC,EAAK5C,UAAYA,EAGnDV,EAAWA,EAAWM,OAAS,GAAK,CAClCQ,MAAOwC,EAAKxC,MAAQ,EACpBC,MAAOA,EACPL,QAASA,GAGXV,EAAWuD,KAAK,CACdzC,MAAO,EACPC,MAAOA,EACPL,QAASA,GAGf,EACAgC,cAAe,SAAuBG,EAAU5C,EAAWC,EAAW0C,GAOpE,IANA,IAAIP,EAASpC,EAAUK,OACnBgC,EAASpC,EAAUI,OACnBC,EAASsC,EAAStC,OAClBC,EAASD,EAASqC,EAClBY,EAAc,EAEXjD,EAAS,EAAI8B,GAAU7B,EAAS,EAAI8B,GAAUR,KAAKT,OAAOpB,EAAUM,EAAS,GAAIL,EAAUM,EAAS,KACzGD,IACAC,IACAgD,IAUF,OAPIA,GACFX,EAAS7C,WAAWuD,KAAK,CACvBzC,MAAO0C,IAIXX,EAAStC,OAASA,EACXC,CACT,EACAa,OAAQ,SAAgBoC,EAAMC,GAC5B,OAAI5B,KAAKJ,QAAQiC,WACR7B,KAAKJ,QAAQiC,WAAWF,EAAMC,GAE9BD,IAASC,GAAS5B,KAAKJ,QAAQkC,YAAcH,EAAKI,gBAAkBH,EAAMG,aAErF,EACA1B,YAAa,SAAqB2B,GAGhC,IAFA,IAAIT,EAAM,GAEDnC,EAAI,EAAGA,EAAI4C,EAAMxD,OAAQY,IAC5B4C,EAAM5C,IACRmC,EAAIE,KAAKO,EAAM5C,IAInB,OAAOmC,CACT,EACAnB,UAAW,SAAmBvB,GAC5B,OAAOA,CACT,EACAyB,SAAU,SAAkBzB,GAC1B,OAAOA,EAAMoD,MAAM,GACrB,EACAnD,KAAM,SAAcoD,GAClB,OAAOA,EAAMpD,KAAK,GACpB,GA+DkB,IAAIf,EAsCxB,IAAIoE,EAAoB,gEACpBC,EAAe,KACfC,EAAW,IAAItE,EAEnBsE,EAAS9C,OAAS,SAAUoC,EAAMC,GAMhC,OALI5B,KAAKJ,QAAQkC,aACfH,EAAOA,EAAKI,cACZH,EAAQA,EAAMG,eAGTJ,IAASC,GAAS5B,KAAKJ,QAAQ0C,mBAAqBF,EAAaG,KAAKZ,KAAUS,EAAaG,KAAKX,EAC3G,EAEAS,EAAS/B,SAAW,SAAUzB,GAI5B,IAFA,IAAI2D,EAAS3D,EAAMoD,MAAM,mCAEhB7C,EAAI,EAAGA,EAAIoD,EAAOhE,OAAS,EAAGY,KAEhCoD,EAAOpD,EAAI,IAAMoD,EAAOpD,EAAI,IAAM+C,EAAkBI,KAAKC,EAAOpD,KAAO+C,EAAkBI,KAAKC,EAAOpD,EAAI,MAC5GoD,EAAOpD,IAAMoD,EAAOpD,EAAI,GACxBoD,EAAOC,OAAOrD,EAAI,EAAG,GACrBA,KAIJ,OAAOoD,CACT,EAaA,IAAIE,EAAW,IAAI3E,EAEnB2E,EAASpC,SAAW,SAAUzB,GAC5B,IAAI8D,EAAW,GACXC,EAAmB/D,EAAMoD,MAAM,aAE9BW,EAAiBA,EAAiBpE,OAAS,IAC9CoE,EAAiBpD,MAInB,IAAK,IAAIJ,EAAI,EAAGA,EAAIwD,EAAiBpE,OAAQY,IAAK,CAChD,IAAIyD,EAAOD,EAAiBxD,GAExBA,EAAI,IAAMY,KAAKJ,QAAQkD,eACzBH,EAASA,EAASnE,OAAS,IAAMqE,GAE7B7C,KAAKJ,QAAQ0C,mBACfO,EAAOA,EAAKE,QAGdJ,EAASlB,KAAKoB,GAElB,CAEA,OAAOF,CACT,EAaA,IAAIK,EAAe,IAAIjF,EAEvBiF,EAAa1C,SAAW,SAAUzB,GAChC,OAAOA,EAAMoD,MAAM,wBACrB,EAMA,IAAIgB,EAAU,IAAIlF,EAUlB,SAASmF,EAAQC,GAaf,OATED,EADoB,mBAAXE,QAAoD,iBAApBA,OAAOC,SACtC,SAAiBF,GACzB,cAAcA,CAChB,EAEU,SAAiBA,GACzB,OAAOA,GAAyB,mBAAXC,QAAyBD,EAAIG,cAAgBF,QAAUD,IAAQC,OAAOzD,UAAY,gBAAkBwD,CAC3H,EAGKD,EAAQC,EACjB,CAtBAF,EAAQ3C,SAAW,SAAUzB,GAC3B,OAAOA,EAAMoD,MAAM,gBACrB,EAyDA,IAAIsB,EAA0BC,OAAO7D,UAAU8D,SAC3CC,EAAW,IAAI3F,EA0BnB,SAAS4F,EAAaR,EAAKS,EAAOC,EAAkBC,EAAUC,GAQ5D,IAAI3E,EAQA4E,EANJ,IATAJ,EAAQA,GAAS,GACjBC,EAAmBA,GAAoB,GAEnCC,IACFX,EAAMW,EAASC,EAAKZ,IAKjB/D,EAAI,EAAGA,EAAIwE,EAAMpF,OAAQY,GAAK,EACjC,GAAIwE,EAAMxE,KAAO+D,EACf,OAAOU,EAAiBzE,GAM5B,GAAI,mBAAqBmE,EAAwBU,KAAKd,GAAM,CAK1D,IAJAS,EAAMnC,KAAK0B,GACXa,EAAmB,IAAIE,MAAMf,EAAI3E,QACjCqF,EAAiBpC,KAAKuC,GAEjB5E,EAAI,EAAGA,EAAI+D,EAAI3E,OAAQY,GAAK,EAC/B4E,EAAiB5E,GAAKuE,EAAaR,EAAI/D,GAAIwE,EAAOC,EAAkBC,EAAUC,GAKhF,OAFAH,EAAMpE,MACNqE,EAAiBrE,MACVwE,CACT,CAMA,GAJIb,GAAOA,EAAIgB,SACbhB,EAAMA,EAAIgB,UAGS,WAAjBjB,EAAQC,IAA6B,OAARA,EAAc,CAC7CS,EAAMnC,KAAK0B,GACXa,EAAmB,CAAC,EACpBH,EAAiBpC,KAAKuC,GAEtB,IACII,EADAC,EAAa,GAGjB,IAAKD,KAAQjB,EAEPA,EAAImB,eAAeF,IACrBC,EAAW5C,KAAK2C,GAMpB,IAFAC,EAAWE,OAENnF,EAAI,EAAGA,EAAIiF,EAAW7F,OAAQY,GAAK,EAEtC4E,EADAI,EAAOC,EAAWjF,IACOuE,EAAaR,EAAIiB,GAAOR,EAAOC,EAAkBC,EAAUM,GAGtFR,EAAMpE,MACNqE,EAAiBrE,KACnB,MACEwE,EAAmBb,EAGrB,OAAOa,CACT,CAxFAN,EAASrF,iBAAkB,EAC3BqF,EAASpD,SAAWoC,EAASpC,SAE7BoD,EAAStD,UAAY,SAAUvB,GAC7B,IAAI2F,EAAgBxE,KAAKJ,QACrB6E,EAAuBD,EAAcC,qBACrCC,EAAwBF,EAAcG,kBACtCA,OAA8C,IAA1BD,EAAmC,SAAUE,EAAGC,GACtE,YAAoB,IAANA,EAAoBJ,EAAuBI,CAC3D,EAAIH,EACJ,MAAwB,iBAAV7F,EAAqBA,EAAQiG,KAAKC,UAAUpB,EAAa9E,EAAO,KAAM,KAAM8F,GAAoBA,EAAmB,KACnI,EAEAjB,EAASnE,OAAS,SAAUoC,EAAMC,GAChC,OAAO7D,EAAK4B,UAAUJ,OAAO0E,KAAKP,EAAU/B,EAAKqD,QAAQ,aAAc,MAAOpD,EAAMoD,QAAQ,aAAc,MAC5G,EA2EA,IAAIC,EAAY,IAAIlH,ECvdb,SAASmH,EAAeC,EAAwBC,EAAsBvD,GAC5E,GAAIuD,EAAO5G,OAAS2G,EAAS3G,OAC5B,OAAO,EAGR,MAAM6G,EAAQF,EAAS3G,OAAS4G,EAAO5G,OACvC,GAAIqD,GACH,IAAK,IAAIyD,EAAI,EAAGA,EAAIF,EAAO5G,OAAQ8G,IAClC,IAAKzD,EAAWsD,EAASE,EAAQC,GAAIF,EAAOE,IAC3C,OAAO,OAIT,IAAK,IAAIA,EAAI,EAAGA,EAAIF,EAAO5G,OAAQ8G,IAClC,GAAKH,EAASE,EAAQC,KAAmBF,EAAOE,GAC/C,OAAO,EAIV,OAAO,CACP,CAmCM,SAASC,EAAYC,EAAoBC,GAC/C,IAAKD,EACJ,MAAM,IAAIE,MAAMD,EAEjB,CD8ZDR,EAAU3E,SAAW,SAAUzB,GAC7B,OAAOA,EAAME,OACf,EAEAkG,EAAUnG,KAAOmG,EAAU5E,YAAc,SAAUxB,GACjD,OAAOA,CACT,EC5Y6C,IAAI8G,IACG,IAAIC,ICnIxD,SAASC,EAAYC,GACpB,MAAMC,EAAuB,CAAC,CAAEC,KAAM,YAAarE,KAAM,GAAIC,MAAO,KAEpE,IAAK,MAAMqE,KAAQH,EAAO,CACzB,MAAMtE,EAAOuE,EAAOA,EAAOvH,OAAS,GAElB,cAAdgD,EAAKwE,MAAsC,cAAdC,EAAKD,MAErCxE,EAAKG,KAAKF,QAAQwE,EAAKtE,MACvBH,EAAKI,MAAMH,QAAQwE,EAAKrE,QACA,YAAdJ,EAAKwE,MAAoC,YAAdC,EAAKD,MAE1CxE,EAAK5C,QAAQ6C,QAAQwE,EAAKrH,SAC1B4C,EAAKvC,MAAMwC,QAAQwE,EAAKhH,QAExB8G,EAAOtE,KAAKwE,EAEb,CAED,OAAOF,CACP,CAEM,SAASG,EAAYvE,EAAoBC,EAAqBC,GACpE,OA+DD,SACCiE,EACAK,EACAC,GAEA,MAAML,EAAuBF,EAAMC,GAEnC,IAAK,IAAI1G,EAAI,EAAGA,EAAI2G,EAAOvH,OAAQY,GAAK,EAAG,CAC1C,MAAMiH,EAAYN,EAAO3G,GACnBkH,EAAUP,EAAO3G,EAAI,GAC3B,GAAKkH,EAIL,GAA6B,IAAzBA,EAAQrH,MAAMT,QACjB,GAAI0G,EAASoB,EAAQ1H,QAASyH,EAAU1E,KAAMwE,GAAc,CAC3D,MAAMI,EAAaD,EAAQ1H,QAAQJ,OAAS6H,EAAU1E,KAAKnD,OACrDgI,EAASF,EAAQ1H,QAAQG,MAAM,EAAGwH,GAClCE,EAAQH,EAAQ1H,QAAQG,MAAMwH,GACpCR,EAAO3G,GAAK,CACX4G,KAAM,UACNpH,QAAS,IAAIyH,EAAU1E,QAAS6E,GAChCvH,MAAO,IAER8G,EAAO3G,EAAI,GAAK,CACf4G,KAAM,YACNrE,KAAM8E,EACN7E,MAAOyE,EAAUzE,MAElB,OACK,GAA+B,IAA3B0E,EAAQ1H,QAAQJ,QACtB0G,EAASoB,EAAQrH,MAAOoH,EAAUzE,MAAOwE,GAAc,CAC1D,MAAMG,EAAaD,EAAQrH,MAAMT,OAAS6H,EAAUzE,MAAMpD,OACpDgI,EAASF,EAAQrH,MAAMF,MAAM,EAAGwH,GAChCE,EAAQH,EAAQrH,MAAMF,MAAMwH,GAClCR,EAAO3G,GAAK,CACX4G,KAAM,UACNpH,QAAS,GACTK,MAAO,IAAIoH,EAAUzE,SAAU4E,IAEhCT,EAAO3G,EAAI,GAAK,CACf4G,KAAM,YACNrE,KAAM0E,EAAU1E,KAChBC,MAAO6E,EAER,CAEF,CAED,OAAOV,CACP,CAjHOW,CAGR,UACC/E,EACAC,EACAC,GAEA,MAAM5D,GFifa0I,EEjfKhF,EFifGiF,EEjfUhF,EFifF7B,EEjfgB,CAAE8B,cFkf7CoD,EAAUhH,KAAK0I,EAAQC,EAAQ7G,IADxC,IAAoB4G,EAAQC,EAAQ7G,EE/enC,IAAI8G,EAAiB,EACjBC,EAAkB,EAEtB,IAAK,MAAMC,KAAU9I,EACpB,GAAI8I,EAAO9H,MACV6H,GAAmBC,EAAOlI,MAAML,YAE1B,CACLwH,KAAM,UACNpH,QAAS,GACTK,MAAO8H,EAAOlI,YAET,GAAIkI,EAAOnI,QACjBiI,GAAkBE,EAAOlI,MAAML,YAEzB,CACLwH,KAAM,UACNpH,QAASmI,EAAOlI,MAChBI,MAAO,QAEF,CACN,MAAMT,EAASuI,EAAOlI,MAAML,OACtBwI,EAAYrF,EAAK5C,MAAM8H,EAAgBA,EAAiBrI,GACxDyI,EAAarF,EAAM7C,MAAM+H,EAAiBA,EAAkBtI,GAClEqI,GAAkBrI,EAClBsI,GAAmBtI,OAEb,CACLwH,KAAM,YACNrE,KAAMqF,EACNpF,MAAOqF,EAER,CAEF,CA5CgBC,CAAYvF,EAAMC,EAAOC,GAAaA,EAAYA,EAClE,CAkHM,SAAUsF,EAAmBrB,GACnC,MAAMsB,EAASvB,EAAMC,GAGrB,IAAK,IAAI1G,EAAI,EAAGA,EAAIgI,EAAO5I,OAAQY,GAAK,EAAG,CAAC,IAAD,EAC1C,MAAMiH,EAAYe,EAAOhI,GACnBkH,EAAO,UAAIc,EAAOhI,EAAI,UAAf,QAAmD,CAC/D4G,KAAM,UACN/G,MAAO,GACPL,QAAS,SAGJ,CAACyH,EAAWC,EAClB,CACD,CCtKM,SAASe,EAAsB1F,EAAcC,GACnD,MAAM,KAAE3D,GA2CF,SACN0D,EACAC,GAEA,IAAIkE,EAAQI,EAASoB,EAAc3F,GAAO2F,EAAc1F,GAAQ2F,EAAUhI,QAE1E,MAAMiI,EAAc,IAAI5B,IAGxBE,EDmHM,UACNA,EACAN,GAEA,IAAK,MAAMuB,KAAUlB,EAAMC,GACN,cAAhBiB,EAAOf,MAAyBR,EAAUuB,SAOvCA,OANA,CACLf,KAAM,UACNpH,QAASmI,EAAOpF,KAChB1C,MAAO8H,EAAOnF,MAMjB,CClIQ6F,CAAgB3B,GAAO4B,IAC9B,MAAMC,EAASC,EAAgBF,EAAE/F,KAAK7C,KAAK,MAAQ8I,EAAgBF,EAAE9F,MAAM9C,KAAK,KAChF,GAAI6I,EAAQ,CACXpC,EAAYmC,EAAE/F,KAAKnD,SAAWkJ,EAAE9F,MAAMpD,QAGtC,IAAK,IAAIY,EAAI,EAAGA,EAAIsI,EAAE/F,KAAKnD,OAAQY,IAAK,CACvC,MAAMyI,EAAIH,EAAE/F,KAAKvC,GACX0I,EAAIJ,EAAE9F,MAAMxC,GAElBmG,GAAaiC,EAAYO,IAAIF,IAC7BL,EAAYQ,IAAIH,EAAGC,GACnBvC,GAAaiC,EAAYO,IAAID,IAC7BN,EAAYQ,IAAIF,EAAGD,EACnB,CACD,CACD,OAAQF,CAAR,IAID,MAAM1J,EAAO,IAAIkJ,EAAarB,IAAQ3G,IAAI8I,EAAeC,cAGnDC,EAAS,IAAIvC,IACbwC,EAAgB,CAACC,EAAkBC,KAA0B,IAAD,IACjE,MAAMC,EAAQf,EAAYgB,IAAIH,GAC9B9C,OAAsBzF,IAAVyI,GAEZJ,EAAOH,IAAIK,EAAOI,KAAKC,IAAL,UAASP,EAAOK,IAAIH,UAApB,QAA8B,EAAGC,IACnDH,EAAOH,IAAIO,EAAOE,KAAKC,IAAL,UAASP,EAAOK,IAAID,UAApB,QAA8B,EAAGD,GAAnD,EAUD,OARArK,EAAK0K,SAAQC,GAAK,CAACA,EAAEjH,KAAK/C,QAASgK,EAAEhH,MAAM3C,SACzC0J,SAAQE,GF/CJ,SACNC,EACAC,GAEA,MAAMhD,EAAgC,GAEtC,IAAIiD,EAAQ,EACZ,IAAK,MAAMC,KAAQH,EAAM,CACxB,MAAMI,EAAWH,EAAWE,EAAMD,KAE5BxH,EAAOuE,EAAOA,EAAOvH,OAAS,GAChCgD,GAAQA,EAAK0H,WAAaA,EAC7B1H,EAAK2H,MAAM1H,KAAKwH,GAEhBlD,EAAOtE,KAAK,CAAEyH,WAAUC,MAAO,CAACF,IAEjC,CAED,OAAOlD,CACP,CE4BiBqD,CAAgBP,GAAKQ,GAAK7B,EAAYO,IAAIsB,OACzDC,QAAOC,GAAKA,EAAEL,WACdM,SAAQD,IACR,MAAME,EAAaF,EAAEJ,MAAMrK,KAAK,IAAIN,OACpC+K,EAAEJ,MAAMK,SAAQH,GAAKjB,EAAciB,EAAGI,IAAtC,IAGK,CAAExL,OAAMkK,SACf,CA5FiBuB,CAAgB/H,EAAMC,GAEjC+H,EAAc1L,EAAK2L,QAAO,CAACC,EAAK9C,IAAW8C,EAAM9C,EAAOpF,KAAKmI,MAAMtL,QAAQ,GAEjF,MAAO,CACNP,KAAMA,EAAKkB,KAAIyJ,GACP,IAAIX,EACV,CAAE6B,MAAOhL,EAAK8J,EAAEjH,KAAKmI,OAAQlL,QAASE,EAAK8J,EAAEjH,KAAK/C,UAClD,CAAEkL,MAAOhL,EAAK8J,EAAEhH,MAAMkI,OAAQ7K,MAAOH,EAAK8J,EAAEhH,MAAM3C,WAGpD0K,cAED,CACD,SAAS7K,EAAKiL,GACb,OAAOA,EAAMjL,KAAK,GAClB,CAUM,MAAMmJ,EAIZ3E,YAAY3B,EAAqBC,GAChC5B,KAAK2B,KAAOA,EACZ3B,KAAK4B,MAAQA,CACb,CAEkB,qBAAKyE,EAAWC,IAClC,OAAO,IAAI2B,EACV,CAAE6B,MAAOzD,EAAU1E,KAAM/C,QAAS0H,EAAQ1H,SAC1C,CAAEkL,MAAOzD,EAAUzE,MAAO3C,MAAOqH,EAAQrH,OAE1C,EA2DF,SAAS2I,EAAgB/I,GAExB,MAEC,gBAAgB0D,KAAK1D,IAErBA,EAAML,QAAU,EAEjB,CAEM,MAAM+I,EAIZjE,YAAY0G,EAAaC,GACxBjK,KAAKgK,IAAMA,EACXhK,KAAKiK,aAAeA,CACpB,CAEDxG,WACC,OAAOzD,KAAKgK,GACZ,CAEY,cAACE,EAAcC,GAC3B,OAAOD,EAAED,eAAiBE,EAAEF,YAC5B,EAGF,MAAMG,EAAgB,iBAAiBC,OACjCC,EAAYF,EAAcpF,QAAQ,MAAO,MACzCuF,EAAoB,GAAEH,MAAkBE,MAAcF,KAE5D,SAAS9C,EAAckD,GACtB,MAAMhI,EAAsB,GAE5B,IAAIhB,EAAO,EACX,MAAMiJ,EAAOC,OAAOH,EAAkB,MACtC,IAAK,IAAII,EAAIA,EAAIF,EAAKnJ,KAAKkJ,IAAU,CACpC,MAAMR,EAAMW,EAAE,GACRV,EAAeU,EAAE,GAAG3F,QAAQ,2BAA4B,IAAI4F,eAAiBD,EAAE,GAErFnI,EAAOf,KAAK,IAAI8F,EAAUyC,EAAKC,IAC/BzI,EAAOmJ,EAAE3B,MAAQgB,EAAIxL,MACrB,CAED,GAAIgD,EAAOgJ,EAAKhM,OAAQ,CACvB,MAAMwL,EAAMQ,EAAKzL,MAAMyC,GACvBgB,EAAOf,KAAK,IAAI8F,EAAUyC,EAAKA,GAC/B,CAED,OAAOxH,CACP,CC5JDvC,KAAK4K,UAAY,EAAGC,MAAQnJ,OAAMC,QAAOmJ,UACxC,MAAM9M,EAAOoJ,EAAsB1F,EAAMC,GACzC3B,KAAK+K,YAAY,CAAE/M,OAAM8M,MAAzB,C","sources":["webpack://picapica-web-client/./node_modules/diff/lib/index.mjs","webpack://picapica-web-client/./src/lib/util.ts","webpack://picapica-web-client/./src/lib/edit.ts","webpack://picapica-web-client/./src/lib/alignment.ts","webpack://picapica-web-client/./src/lib/alignment.worker.ts"],"sourcesContent":["function Diff() {}\n\nDiff.prototype = {\n  diff: function diff(oldString, newString) {\n    var options = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : {};\n    var callback = options.callback;\n\n    if (typeof options === 'function') {\n      callback = options;\n      options = {};\n    }\n\n    this.options = options;\n    var self = this;\n\n    function done(value) {\n      if (callback) {\n        setTimeout(function () {\n          callback(undefined, value);\n        }, 0);\n        return true;\n      } else {\n        return value;\n      }\n    } // Allow subclasses to massage the input prior to running\n\n\n    oldString = this.castInput(oldString);\n    newString = this.castInput(newString);\n    oldString = this.removeEmpty(this.tokenize(oldString));\n    newString = this.removeEmpty(this.tokenize(newString));\n    var newLen = newString.length,\n        oldLen = oldString.length;\n    var editLength = 1;\n    var maxEditLength = newLen + oldLen;\n    var bestPath = [{\n      newPos: -1,\n      components: []\n    }]; // Seed editLength = 0, i.e. the content starts with the same values\n\n    var oldPos = this.extractCommon(bestPath[0], newString, oldString, 0);\n\n    if (bestPath[0].newPos + 1 >= newLen && oldPos + 1 >= oldLen) {\n      // Identity per the equality and tokenizer\n      return done([{\n        value: this.join(newString),\n        count: newString.length\n      }]);\n    } // Main worker method. checks all permutations of a given edit length for acceptance.\n\n\n    function execEditLength() {\n      for (var diagonalPath = -1 * editLength; diagonalPath <= editLength; diagonalPath += 2) {\n        var basePath = void 0;\n\n        var addPath = bestPath[diagonalPath - 1],\n            removePath = bestPath[diagonalPath + 1],\n            _oldPos = (removePath ? removePath.newPos : 0) - diagonalPath;\n\n        if (addPath) {\n          // No one else is going to attempt to use this value, clear it\n          bestPath[diagonalPath - 1] = undefined;\n        }\n\n        var canAdd = addPath && addPath.newPos + 1 < newLen,\n            canRemove = removePath && 0 <= _oldPos && _oldPos < oldLen;\n\n        if (!canAdd && !canRemove) {\n          // If this path is a terminal then prune\n          bestPath[diagonalPath] = undefined;\n          continue;\n        } // Select the diagonal that we want to branch from. We select the prior\n        // path whose position in the new string is the farthest from the origin\n        // and does not pass the bounds of the diff graph\n\n\n        if (!canAdd || canRemove && addPath.newPos < removePath.newPos) {\n          basePath = clonePath(removePath);\n          self.pushComponent(basePath.components, undefined, true);\n        } else {\n          basePath = addPath; // No need to clone, we've pulled it from the list\n\n          basePath.newPos++;\n          self.pushComponent(basePath.components, true, undefined);\n        }\n\n        _oldPos = self.extractCommon(basePath, newString, oldString, diagonalPath); // If we have hit the end of both strings, then we are done\n\n        if (basePath.newPos + 1 >= newLen && _oldPos + 1 >= oldLen) {\n          return done(buildValues(self, basePath.components, newString, oldString, self.useLongestToken));\n        } else {\n          // Otherwise track this path as a potential candidate and continue.\n          bestPath[diagonalPath] = basePath;\n        }\n      }\n\n      editLength++;\n    } // Performs the length of edit iteration. Is a bit fugly as this has to support the\n    // sync and async mode which is never fun. Loops over execEditLength until a value\n    // is produced.\n\n\n    if (callback) {\n      (function exec() {\n        setTimeout(function () {\n          // This should not happen, but we want to be safe.\n\n          /* istanbul ignore next */\n          if (editLength > maxEditLength) {\n            return callback();\n          }\n\n          if (!execEditLength()) {\n            exec();\n          }\n        }, 0);\n      })();\n    } else {\n      while (editLength <= maxEditLength) {\n        var ret = execEditLength();\n\n        if (ret) {\n          return ret;\n        }\n      }\n    }\n  },\n  pushComponent: function pushComponent(components, added, removed) {\n    var last = components[components.length - 1];\n\n    if (last && last.added === added && last.removed === removed) {\n      // We need to clone here as the component clone operation is just\n      // as shallow array clone\n      components[components.length - 1] = {\n        count: last.count + 1,\n        added: added,\n        removed: removed\n      };\n    } else {\n      components.push({\n        count: 1,\n        added: added,\n        removed: removed\n      });\n    }\n  },\n  extractCommon: function extractCommon(basePath, newString, oldString, diagonalPath) {\n    var newLen = newString.length,\n        oldLen = oldString.length,\n        newPos = basePath.newPos,\n        oldPos = newPos - diagonalPath,\n        commonCount = 0;\n\n    while (newPos + 1 < newLen && oldPos + 1 < oldLen && this.equals(newString[newPos + 1], oldString[oldPos + 1])) {\n      newPos++;\n      oldPos++;\n      commonCount++;\n    }\n\n    if (commonCount) {\n      basePath.components.push({\n        count: commonCount\n      });\n    }\n\n    basePath.newPos = newPos;\n    return oldPos;\n  },\n  equals: function equals(left, right) {\n    if (this.options.comparator) {\n      return this.options.comparator(left, right);\n    } else {\n      return left === right || this.options.ignoreCase && left.toLowerCase() === right.toLowerCase();\n    }\n  },\n  removeEmpty: function removeEmpty(array) {\n    var ret = [];\n\n    for (var i = 0; i < array.length; i++) {\n      if (array[i]) {\n        ret.push(array[i]);\n      }\n    }\n\n    return ret;\n  },\n  castInput: function castInput(value) {\n    return value;\n  },\n  tokenize: function tokenize(value) {\n    return value.split('');\n  },\n  join: function join(chars) {\n    return chars.join('');\n  }\n};\n\nfunction buildValues(diff, components, newString, oldString, useLongestToken) {\n  var componentPos = 0,\n      componentLen = components.length,\n      newPos = 0,\n      oldPos = 0;\n\n  for (; componentPos < componentLen; componentPos++) {\n    var component = components[componentPos];\n\n    if (!component.removed) {\n      if (!component.added && useLongestToken) {\n        var value = newString.slice(newPos, newPos + component.count);\n        value = value.map(function (value, i) {\n          var oldValue = oldString[oldPos + i];\n          return oldValue.length > value.length ? oldValue : value;\n        });\n        component.value = diff.join(value);\n      } else {\n        component.value = diff.join(newString.slice(newPos, newPos + component.count));\n      }\n\n      newPos += component.count; // Common case\n\n      if (!component.added) {\n        oldPos += component.count;\n      }\n    } else {\n      component.value = diff.join(oldString.slice(oldPos, oldPos + component.count));\n      oldPos += component.count; // Reverse add and remove so removes are output first to match common convention\n      // The diffing algorithm is tied to add then remove output and this is the simplest\n      // route to get the desired output with minimal overhead.\n\n      if (componentPos && components[componentPos - 1].added) {\n        var tmp = components[componentPos - 1];\n        components[componentPos - 1] = components[componentPos];\n        components[componentPos] = tmp;\n      }\n    }\n  } // Special case handle for when one terminal is ignored (i.e. whitespace).\n  // For this case we merge the terminal into the prior string and drop the change.\n  // This is only available for string mode.\n\n\n  var lastComponent = components[componentLen - 1];\n\n  if (componentLen > 1 && typeof lastComponent.value === 'string' && (lastComponent.added || lastComponent.removed) && diff.equals('', lastComponent.value)) {\n    components[componentLen - 2].value += lastComponent.value;\n    components.pop();\n  }\n\n  return components;\n}\n\nfunction clonePath(path) {\n  return {\n    newPos: path.newPos,\n    components: path.components.slice(0)\n  };\n}\n\nvar characterDiff = new Diff();\n\nfunction diffChars(oldStr, newStr, options) {\n  return characterDiff.diff(oldStr, newStr, options);\n}\n\nfunction generateOptions(options, defaults) {\n  if (typeof options === 'function') {\n    defaults.callback = options;\n  } else if (options) {\n    for (var name in options) {\n      /* istanbul ignore else */\n      if (options.hasOwnProperty(name)) {\n        defaults[name] = options[name];\n      }\n    }\n  }\n\n  return defaults;\n} //\n// Ranges and exceptions:\n// Latin-1 Supplement, 0080–00FF\n//  - U+00D7  × Multiplication sign\n//  - U+00F7  ÷ Division sign\n// Latin Extended-A, 0100–017F\n// Latin Extended-B, 0180–024F\n// IPA Extensions, 0250–02AF\n// Spacing Modifier Letters, 02B0–02FF\n//  - U+02C7  ˇ &#711;  Caron\n//  - U+02D8  ˘ &#728;  Breve\n//  - U+02D9  ˙ &#729;  Dot Above\n//  - U+02DA  ˚ &#730;  Ring Above\n//  - U+02DB  ˛ &#731;  Ogonek\n//  - U+02DC  ˜ &#732;  Small Tilde\n//  - U+02DD  ˝ &#733;  Double Acute Accent\n// Latin Extended Additional, 1E00–1EFF\n\n\nvar extendedWordChars = /^[A-Za-z\\xC0-\\u02C6\\u02C8-\\u02D7\\u02DE-\\u02FF\\u1E00-\\u1EFF]+$/;\nvar reWhitespace = /\\S/;\nvar wordDiff = new Diff();\n\nwordDiff.equals = function (left, right) {\n  if (this.options.ignoreCase) {\n    left = left.toLowerCase();\n    right = right.toLowerCase();\n  }\n\n  return left === right || this.options.ignoreWhitespace && !reWhitespace.test(left) && !reWhitespace.test(right);\n};\n\nwordDiff.tokenize = function (value) {\n  // All whitespace symbols except newline group into one token, each newline - in separate token\n  var tokens = value.split(/([^\\S\\r\\n]+|[()[\\]{}'\"\\r\\n]|\\b)/); // Join the boundary splits that we do not consider to be boundaries. This is primarily the extended Latin character set.\n\n  for (var i = 0; i < tokens.length - 1; i++) {\n    // If we have an empty string in the next field and we have only word chars before and after, merge\n    if (!tokens[i + 1] && tokens[i + 2] && extendedWordChars.test(tokens[i]) && extendedWordChars.test(tokens[i + 2])) {\n      tokens[i] += tokens[i + 2];\n      tokens.splice(i + 1, 2);\n      i--;\n    }\n  }\n\n  return tokens;\n};\n\nfunction diffWords(oldStr, newStr, options) {\n  options = generateOptions(options, {\n    ignoreWhitespace: true\n  });\n  return wordDiff.diff(oldStr, newStr, options);\n}\n\nfunction diffWordsWithSpace(oldStr, newStr, options) {\n  return wordDiff.diff(oldStr, newStr, options);\n}\n\nvar lineDiff = new Diff();\n\nlineDiff.tokenize = function (value) {\n  var retLines = [],\n      linesAndNewlines = value.split(/(\\n|\\r\\n)/); // Ignore the final empty token that occurs if the string ends with a new line\n\n  if (!linesAndNewlines[linesAndNewlines.length - 1]) {\n    linesAndNewlines.pop();\n  } // Merge the content and line separators into single tokens\n\n\n  for (var i = 0; i < linesAndNewlines.length; i++) {\n    var line = linesAndNewlines[i];\n\n    if (i % 2 && !this.options.newlineIsToken) {\n      retLines[retLines.length - 1] += line;\n    } else {\n      if (this.options.ignoreWhitespace) {\n        line = line.trim();\n      }\n\n      retLines.push(line);\n    }\n  }\n\n  return retLines;\n};\n\nfunction diffLines(oldStr, newStr, callback) {\n  return lineDiff.diff(oldStr, newStr, callback);\n}\n\nfunction diffTrimmedLines(oldStr, newStr, callback) {\n  var options = generateOptions(callback, {\n    ignoreWhitespace: true\n  });\n  return lineDiff.diff(oldStr, newStr, options);\n}\n\nvar sentenceDiff = new Diff();\n\nsentenceDiff.tokenize = function (value) {\n  return value.split(/(\\S.+?[.!?])(?=\\s+|$)/);\n};\n\nfunction diffSentences(oldStr, newStr, callback) {\n  return sentenceDiff.diff(oldStr, newStr, callback);\n}\n\nvar cssDiff = new Diff();\n\ncssDiff.tokenize = function (value) {\n  return value.split(/([{}:;,]|\\s+)/);\n};\n\nfunction diffCss(oldStr, newStr, callback) {\n  return cssDiff.diff(oldStr, newStr, callback);\n}\n\nfunction _typeof(obj) {\n  \"@babel/helpers - typeof\";\n\n  if (typeof Symbol === \"function\" && typeof Symbol.iterator === \"symbol\") {\n    _typeof = function _typeof(obj) {\n      return typeof obj;\n    };\n  } else {\n    _typeof = function _typeof(obj) {\n      return obj && typeof Symbol === \"function\" && obj.constructor === Symbol && obj !== Symbol.prototype ? \"symbol\" : typeof obj;\n    };\n  }\n\n  return _typeof(obj);\n}\n\nfunction _toConsumableArray(arr) {\n  return _arrayWithoutHoles(arr) || _iterableToArray(arr) || _unsupportedIterableToArray(arr) || _nonIterableSpread();\n}\n\nfunction _arrayWithoutHoles(arr) {\n  if (Array.isArray(arr)) return _arrayLikeToArray(arr);\n}\n\nfunction _iterableToArray(iter) {\n  if (typeof Symbol !== \"undefined\" && Symbol.iterator in Object(iter)) return Array.from(iter);\n}\n\nfunction _unsupportedIterableToArray(o, minLen) {\n  if (!o) return;\n  if (typeof o === \"string\") return _arrayLikeToArray(o, minLen);\n  var n = Object.prototype.toString.call(o).slice(8, -1);\n  if (n === \"Object\" && o.constructor) n = o.constructor.name;\n  if (n === \"Map\" || n === \"Set\") return Array.from(o);\n  if (n === \"Arguments\" || /^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(n)) return _arrayLikeToArray(o, minLen);\n}\n\nfunction _arrayLikeToArray(arr, len) {\n  if (len == null || len > arr.length) len = arr.length;\n\n  for (var i = 0, arr2 = new Array(len); i < len; i++) {\n    arr2[i] = arr[i];\n  }\n\n  return arr2;\n}\n\nfunction _nonIterableSpread() {\n  throw new TypeError(\"Invalid attempt to spread non-iterable instance.\\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.\");\n}\n\nvar objectPrototypeToString = Object.prototype.toString;\nvar jsonDiff = new Diff(); // Discriminate between two lines of pretty-printed, serialized JSON where one of them has a\n// dangling comma and the other doesn't. Turns out including the dangling comma yields the nicest output:\n\njsonDiff.useLongestToken = true;\njsonDiff.tokenize = lineDiff.tokenize;\n\njsonDiff.castInput = function (value) {\n  var _this$options = this.options,\n      undefinedReplacement = _this$options.undefinedReplacement,\n      _this$options$stringi = _this$options.stringifyReplacer,\n      stringifyReplacer = _this$options$stringi === void 0 ? function (k, v) {\n    return typeof v === 'undefined' ? undefinedReplacement : v;\n  } : _this$options$stringi;\n  return typeof value === 'string' ? value : JSON.stringify(canonicalize(value, null, null, stringifyReplacer), stringifyReplacer, '  ');\n};\n\njsonDiff.equals = function (left, right) {\n  return Diff.prototype.equals.call(jsonDiff, left.replace(/,([\\r\\n])/g, '$1'), right.replace(/,([\\r\\n])/g, '$1'));\n};\n\nfunction diffJson(oldObj, newObj, options) {\n  return jsonDiff.diff(oldObj, newObj, options);\n} // This function handles the presence of circular references by bailing out when encountering an\n// object that is already on the \"stack\" of items being processed. Accepts an optional replacer\n\n\nfunction canonicalize(obj, stack, replacementStack, replacer, key) {\n  stack = stack || [];\n  replacementStack = replacementStack || [];\n\n  if (replacer) {\n    obj = replacer(key, obj);\n  }\n\n  var i;\n\n  for (i = 0; i < stack.length; i += 1) {\n    if (stack[i] === obj) {\n      return replacementStack[i];\n    }\n  }\n\n  var canonicalizedObj;\n\n  if ('[object Array]' === objectPrototypeToString.call(obj)) {\n    stack.push(obj);\n    canonicalizedObj = new Array(obj.length);\n    replacementStack.push(canonicalizedObj);\n\n    for (i = 0; i < obj.length; i += 1) {\n      canonicalizedObj[i] = canonicalize(obj[i], stack, replacementStack, replacer, key);\n    }\n\n    stack.pop();\n    replacementStack.pop();\n    return canonicalizedObj;\n  }\n\n  if (obj && obj.toJSON) {\n    obj = obj.toJSON();\n  }\n\n  if (_typeof(obj) === 'object' && obj !== null) {\n    stack.push(obj);\n    canonicalizedObj = {};\n    replacementStack.push(canonicalizedObj);\n\n    var sortedKeys = [],\n        _key;\n\n    for (_key in obj) {\n      /* istanbul ignore else */\n      if (obj.hasOwnProperty(_key)) {\n        sortedKeys.push(_key);\n      }\n    }\n\n    sortedKeys.sort();\n\n    for (i = 0; i < sortedKeys.length; i += 1) {\n      _key = sortedKeys[i];\n      canonicalizedObj[_key] = canonicalize(obj[_key], stack, replacementStack, replacer, _key);\n    }\n\n    stack.pop();\n    replacementStack.pop();\n  } else {\n    canonicalizedObj = obj;\n  }\n\n  return canonicalizedObj;\n}\n\nvar arrayDiff = new Diff();\n\narrayDiff.tokenize = function (value) {\n  return value.slice();\n};\n\narrayDiff.join = arrayDiff.removeEmpty = function (value) {\n  return value;\n};\n\nfunction diffArrays(oldArr, newArr, callback) {\n  return arrayDiff.diff(oldArr, newArr, callback);\n}\n\nfunction parsePatch(uniDiff) {\n  var options = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n  var diffstr = uniDiff.split(/\\r\\n|[\\n\\v\\f\\r\\x85]/),\n      delimiters = uniDiff.match(/\\r\\n|[\\n\\v\\f\\r\\x85]/g) || [],\n      list = [],\n      i = 0;\n\n  function parseIndex() {\n    var index = {};\n    list.push(index); // Parse diff metadata\n\n    while (i < diffstr.length) {\n      var line = diffstr[i]; // File header found, end parsing diff metadata\n\n      if (/^(\\-\\-\\-|\\+\\+\\+|@@)\\s/.test(line)) {\n        break;\n      } // Diff index\n\n\n      var header = /^(?:Index:|diff(?: -r \\w+)+)\\s+(.+?)\\s*$/.exec(line);\n\n      if (header) {\n        index.index = header[1];\n      }\n\n      i++;\n    } // Parse file headers if they are defined. Unified diff requires them, but\n    // there's no technical issues to have an isolated hunk without file header\n\n\n    parseFileHeader(index);\n    parseFileHeader(index); // Parse hunks\n\n    index.hunks = [];\n\n    while (i < diffstr.length) {\n      var _line = diffstr[i];\n\n      if (/^(Index:|diff|\\-\\-\\-|\\+\\+\\+)\\s/.test(_line)) {\n        break;\n      } else if (/^@@/.test(_line)) {\n        index.hunks.push(parseHunk());\n      } else if (_line && options.strict) {\n        // Ignore unexpected content unless in strict mode\n        throw new Error('Unknown line ' + (i + 1) + ' ' + JSON.stringify(_line));\n      } else {\n        i++;\n      }\n    }\n  } // Parses the --- and +++ headers, if none are found, no lines\n  // are consumed.\n\n\n  function parseFileHeader(index) {\n    var fileHeader = /^(---|\\+\\+\\+)\\s+(.*)$/.exec(diffstr[i]);\n\n    if (fileHeader) {\n      var keyPrefix = fileHeader[1] === '---' ? 'old' : 'new';\n      var data = fileHeader[2].split('\\t', 2);\n      var fileName = data[0].replace(/\\\\\\\\/g, '\\\\');\n\n      if (/^\".*\"$/.test(fileName)) {\n        fileName = fileName.substr(1, fileName.length - 2);\n      }\n\n      index[keyPrefix + 'FileName'] = fileName;\n      index[keyPrefix + 'Header'] = (data[1] || '').trim();\n      i++;\n    }\n  } // Parses a hunk\n  // This assumes that we are at the start of a hunk.\n\n\n  function parseHunk() {\n    var chunkHeaderIndex = i,\n        chunkHeaderLine = diffstr[i++],\n        chunkHeader = chunkHeaderLine.split(/@@ -(\\d+)(?:,(\\d+))? \\+(\\d+)(?:,(\\d+))? @@/);\n    var hunk = {\n      oldStart: +chunkHeader[1],\n      oldLines: typeof chunkHeader[2] === 'undefined' ? 1 : +chunkHeader[2],\n      newStart: +chunkHeader[3],\n      newLines: typeof chunkHeader[4] === 'undefined' ? 1 : +chunkHeader[4],\n      lines: [],\n      linedelimiters: []\n    }; // Unified Diff Format quirk: If the chunk size is 0,\n    // the first number is one lower than one would expect.\n    // https://www.artima.com/weblogs/viewpost.jsp?thread=164293\n\n    if (hunk.oldLines === 0) {\n      hunk.oldStart += 1;\n    }\n\n    if (hunk.newLines === 0) {\n      hunk.newStart += 1;\n    }\n\n    var addCount = 0,\n        removeCount = 0;\n\n    for (; i < diffstr.length; i++) {\n      // Lines starting with '---' could be mistaken for the \"remove line\" operation\n      // But they could be the header for the next file. Therefore prune such cases out.\n      if (diffstr[i].indexOf('--- ') === 0 && i + 2 < diffstr.length && diffstr[i + 1].indexOf('+++ ') === 0 && diffstr[i + 2].indexOf('@@') === 0) {\n        break;\n      }\n\n      var operation = diffstr[i].length == 0 && i != diffstr.length - 1 ? ' ' : diffstr[i][0];\n\n      if (operation === '+' || operation === '-' || operation === ' ' || operation === '\\\\') {\n        hunk.lines.push(diffstr[i]);\n        hunk.linedelimiters.push(delimiters[i] || '\\n');\n\n        if (operation === '+') {\n          addCount++;\n        } else if (operation === '-') {\n          removeCount++;\n        } else if (operation === ' ') {\n          addCount++;\n          removeCount++;\n        }\n      } else {\n        break;\n      }\n    } // Handle the empty block count case\n\n\n    if (!addCount && hunk.newLines === 1) {\n      hunk.newLines = 0;\n    }\n\n    if (!removeCount && hunk.oldLines === 1) {\n      hunk.oldLines = 0;\n    } // Perform optional sanity checking\n\n\n    if (options.strict) {\n      if (addCount !== hunk.newLines) {\n        throw new Error('Added line count did not match for hunk at line ' + (chunkHeaderIndex + 1));\n      }\n\n      if (removeCount !== hunk.oldLines) {\n        throw new Error('Removed line count did not match for hunk at line ' + (chunkHeaderIndex + 1));\n      }\n    }\n\n    return hunk;\n  }\n\n  while (i < diffstr.length) {\n    parseIndex();\n  }\n\n  return list;\n} // Iterator that traverses in the range of [min, max], stepping\n// by distance from a given start position. I.e. for [0, 4], with\n// start of 2, this will iterate 2, 3, 1, 4, 0.\n\n\nfunction distanceIterator(start, minLine, maxLine) {\n  var wantForward = true,\n      backwardExhausted = false,\n      forwardExhausted = false,\n      localOffset = 1;\n  return function iterator() {\n    if (wantForward && !forwardExhausted) {\n      if (backwardExhausted) {\n        localOffset++;\n      } else {\n        wantForward = false;\n      } // Check if trying to fit beyond text length, and if not, check it fits\n      // after offset location (or desired location on first iteration)\n\n\n      if (start + localOffset <= maxLine) {\n        return localOffset;\n      }\n\n      forwardExhausted = true;\n    }\n\n    if (!backwardExhausted) {\n      if (!forwardExhausted) {\n        wantForward = true;\n      } // Check if trying to fit before text beginning, and if not, check it fits\n      // before offset location\n\n\n      if (minLine <= start - localOffset) {\n        return -localOffset++;\n      }\n\n      backwardExhausted = true;\n      return iterator();\n    } // We tried to fit hunk before text beginning and beyond text length, then\n    // hunk can't fit on the text. Return undefined\n\n  };\n}\n\nfunction applyPatch(source, uniDiff) {\n  var options = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : {};\n\n  if (typeof uniDiff === 'string') {\n    uniDiff = parsePatch(uniDiff);\n  }\n\n  if (Array.isArray(uniDiff)) {\n    if (uniDiff.length > 1) {\n      throw new Error('applyPatch only works with a single input.');\n    }\n\n    uniDiff = uniDiff[0];\n  } // Apply the diff to the input\n\n\n  var lines = source.split(/\\r\\n|[\\n\\v\\f\\r\\x85]/),\n      delimiters = source.match(/\\r\\n|[\\n\\v\\f\\r\\x85]/g) || [],\n      hunks = uniDiff.hunks,\n      compareLine = options.compareLine || function (lineNumber, line, operation, patchContent) {\n    return line === patchContent;\n  },\n      errorCount = 0,\n      fuzzFactor = options.fuzzFactor || 0,\n      minLine = 0,\n      offset = 0,\n      removeEOFNL,\n      addEOFNL;\n  /**\n   * Checks if the hunk exactly fits on the provided location\n   */\n\n\n  function hunkFits(hunk, toPos) {\n    for (var j = 0; j < hunk.lines.length; j++) {\n      var line = hunk.lines[j],\n          operation = line.length > 0 ? line[0] : ' ',\n          content = line.length > 0 ? line.substr(1) : line;\n\n      if (operation === ' ' || operation === '-') {\n        // Context sanity check\n        if (!compareLine(toPos + 1, lines[toPos], operation, content)) {\n          errorCount++;\n\n          if (errorCount > fuzzFactor) {\n            return false;\n          }\n        }\n\n        toPos++;\n      }\n    }\n\n    return true;\n  } // Search best fit offsets for each hunk based on the previous ones\n\n\n  for (var i = 0; i < hunks.length; i++) {\n    var hunk = hunks[i],\n        maxLine = lines.length - hunk.oldLines,\n        localOffset = 0,\n        toPos = offset + hunk.oldStart - 1;\n    var iterator = distanceIterator(toPos, minLine, maxLine);\n\n    for (; localOffset !== undefined; localOffset = iterator()) {\n      if (hunkFits(hunk, toPos + localOffset)) {\n        hunk.offset = offset += localOffset;\n        break;\n      }\n    }\n\n    if (localOffset === undefined) {\n      return false;\n    } // Set lower text limit to end of the current hunk, so next ones don't try\n    // to fit over already patched text\n\n\n    minLine = hunk.offset + hunk.oldStart + hunk.oldLines;\n  } // Apply patch hunks\n\n\n  var diffOffset = 0;\n\n  for (var _i = 0; _i < hunks.length; _i++) {\n    var _hunk = hunks[_i],\n        _toPos = _hunk.oldStart + _hunk.offset + diffOffset - 1;\n\n    diffOffset += _hunk.newLines - _hunk.oldLines;\n\n    for (var j = 0; j < _hunk.lines.length; j++) {\n      var line = _hunk.lines[j],\n          operation = line.length > 0 ? line[0] : ' ',\n          content = line.length > 0 ? line.substr(1) : line,\n          delimiter = _hunk.linedelimiters[j];\n\n      if (operation === ' ') {\n        _toPos++;\n      } else if (operation === '-') {\n        lines.splice(_toPos, 1);\n        delimiters.splice(_toPos, 1);\n        /* istanbul ignore else */\n      } else if (operation === '+') {\n        lines.splice(_toPos, 0, content);\n        delimiters.splice(_toPos, 0, delimiter);\n        _toPos++;\n      } else if (operation === '\\\\') {\n        var previousOperation = _hunk.lines[j - 1] ? _hunk.lines[j - 1][0] : null;\n\n        if (previousOperation === '+') {\n          removeEOFNL = true;\n        } else if (previousOperation === '-') {\n          addEOFNL = true;\n        }\n      }\n    }\n  } // Handle EOFNL insertion/removal\n\n\n  if (removeEOFNL) {\n    while (!lines[lines.length - 1]) {\n      lines.pop();\n      delimiters.pop();\n    }\n  } else if (addEOFNL) {\n    lines.push('');\n    delimiters.push('\\n');\n  }\n\n  for (var _k = 0; _k < lines.length - 1; _k++) {\n    lines[_k] = lines[_k] + delimiters[_k];\n  }\n\n  return lines.join('');\n} // Wrapper that supports multiple file patches via callbacks.\n\n\nfunction applyPatches(uniDiff, options) {\n  if (typeof uniDiff === 'string') {\n    uniDiff = parsePatch(uniDiff);\n  }\n\n  var currentIndex = 0;\n\n  function processIndex() {\n    var index = uniDiff[currentIndex++];\n\n    if (!index) {\n      return options.complete();\n    }\n\n    options.loadFile(index, function (err, data) {\n      if (err) {\n        return options.complete(err);\n      }\n\n      var updatedContent = applyPatch(data, index, options);\n      options.patched(index, updatedContent, function (err) {\n        if (err) {\n          return options.complete(err);\n        }\n\n        processIndex();\n      });\n    });\n  }\n\n  processIndex();\n}\n\nfunction structuredPatch(oldFileName, newFileName, oldStr, newStr, oldHeader, newHeader, options) {\n  if (!options) {\n    options = {};\n  }\n\n  if (typeof options.context === 'undefined') {\n    options.context = 4;\n  }\n\n  var diff = diffLines(oldStr, newStr, options);\n  diff.push({\n    value: '',\n    lines: []\n  }); // Append an empty value to make cleanup easier\n\n  function contextLines(lines) {\n    return lines.map(function (entry) {\n      return ' ' + entry;\n    });\n  }\n\n  var hunks = [];\n  var oldRangeStart = 0,\n      newRangeStart = 0,\n      curRange = [],\n      oldLine = 1,\n      newLine = 1;\n\n  var _loop = function _loop(i) {\n    var current = diff[i],\n        lines = current.lines || current.value.replace(/\\n$/, '').split('\\n');\n    current.lines = lines;\n\n    if (current.added || current.removed) {\n      var _curRange; // If we have previous context, start with that\n\n\n      if (!oldRangeStart) {\n        var prev = diff[i - 1];\n        oldRangeStart = oldLine;\n        newRangeStart = newLine;\n\n        if (prev) {\n          curRange = options.context > 0 ? contextLines(prev.lines.slice(-options.context)) : [];\n          oldRangeStart -= curRange.length;\n          newRangeStart -= curRange.length;\n        }\n      } // Output our changes\n\n\n      (_curRange = curRange).push.apply(_curRange, _toConsumableArray(lines.map(function (entry) {\n        return (current.added ? '+' : '-') + entry;\n      }))); // Track the updated file position\n\n\n      if (current.added) {\n        newLine += lines.length;\n      } else {\n        oldLine += lines.length;\n      }\n    } else {\n      // Identical context lines. Track line changes\n      if (oldRangeStart) {\n        // Close out any changes that have been output (or join overlapping)\n        if (lines.length <= options.context * 2 && i < diff.length - 2) {\n          var _curRange2; // Overlapping\n\n\n          (_curRange2 = curRange).push.apply(_curRange2, _toConsumableArray(contextLines(lines)));\n        } else {\n          var _curRange3; // end the range and output\n\n\n          var contextSize = Math.min(lines.length, options.context);\n\n          (_curRange3 = curRange).push.apply(_curRange3, _toConsumableArray(contextLines(lines.slice(0, contextSize))));\n\n          var hunk = {\n            oldStart: oldRangeStart,\n            oldLines: oldLine - oldRangeStart + contextSize,\n            newStart: newRangeStart,\n            newLines: newLine - newRangeStart + contextSize,\n            lines: curRange\n          };\n\n          if (i >= diff.length - 2 && lines.length <= options.context) {\n            // EOF is inside this hunk\n            var oldEOFNewline = /\\n$/.test(oldStr);\n            var newEOFNewline = /\\n$/.test(newStr);\n            var noNlBeforeAdds = lines.length == 0 && curRange.length > hunk.oldLines;\n\n            if (!oldEOFNewline && noNlBeforeAdds && oldStr.length > 0) {\n              // special case: old has no eol and no trailing context; no-nl can end up before adds\n              // however, if the old file is empty, do not output the no-nl line\n              curRange.splice(hunk.oldLines, 0, '\\\\ No newline at end of file');\n            }\n\n            if (!oldEOFNewline && !noNlBeforeAdds || !newEOFNewline) {\n              curRange.push('\\\\ No newline at end of file');\n            }\n          }\n\n          hunks.push(hunk);\n          oldRangeStart = 0;\n          newRangeStart = 0;\n          curRange = [];\n        }\n      }\n\n      oldLine += lines.length;\n      newLine += lines.length;\n    }\n  };\n\n  for (var i = 0; i < diff.length; i++) {\n    _loop(i);\n  }\n\n  return {\n    oldFileName: oldFileName,\n    newFileName: newFileName,\n    oldHeader: oldHeader,\n    newHeader: newHeader,\n    hunks: hunks\n  };\n}\n\nfunction formatPatch(diff) {\n  var ret = [];\n\n  if (diff.oldFileName == diff.newFileName) {\n    ret.push('Index: ' + diff.oldFileName);\n  }\n\n  ret.push('===================================================================');\n  ret.push('--- ' + diff.oldFileName + (typeof diff.oldHeader === 'undefined' ? '' : '\\t' + diff.oldHeader));\n  ret.push('+++ ' + diff.newFileName + (typeof diff.newHeader === 'undefined' ? '' : '\\t' + diff.newHeader));\n\n  for (var i = 0; i < diff.hunks.length; i++) {\n    var hunk = diff.hunks[i]; // Unified Diff Format quirk: If the chunk size is 0,\n    // the first number is one lower than one would expect.\n    // https://www.artima.com/weblogs/viewpost.jsp?thread=164293\n\n    if (hunk.oldLines === 0) {\n      hunk.oldStart -= 1;\n    }\n\n    if (hunk.newLines === 0) {\n      hunk.newStart -= 1;\n    }\n\n    ret.push('@@ -' + hunk.oldStart + ',' + hunk.oldLines + ' +' + hunk.newStart + ',' + hunk.newLines + ' @@');\n    ret.push.apply(ret, hunk.lines);\n  }\n\n  return ret.join('\\n') + '\\n';\n}\n\nfunction createTwoFilesPatch(oldFileName, newFileName, oldStr, newStr, oldHeader, newHeader, options) {\n  return formatPatch(structuredPatch(oldFileName, newFileName, oldStr, newStr, oldHeader, newHeader, options));\n}\n\nfunction createPatch(fileName, oldStr, newStr, oldHeader, newHeader, options) {\n  return createTwoFilesPatch(fileName, fileName, oldStr, newStr, oldHeader, newHeader, options);\n}\n\nfunction arrayEqual(a, b) {\n  if (a.length !== b.length) {\n    return false;\n  }\n\n  return arrayStartsWith(a, b);\n}\n\nfunction arrayStartsWith(array, start) {\n  if (start.length > array.length) {\n    return false;\n  }\n\n  for (var i = 0; i < start.length; i++) {\n    if (start[i] !== array[i]) {\n      return false;\n    }\n  }\n\n  return true;\n}\n\nfunction calcLineCount(hunk) {\n  var _calcOldNewLineCount = calcOldNewLineCount(hunk.lines),\n      oldLines = _calcOldNewLineCount.oldLines,\n      newLines = _calcOldNewLineCount.newLines;\n\n  if (oldLines !== undefined) {\n    hunk.oldLines = oldLines;\n  } else {\n    delete hunk.oldLines;\n  }\n\n  if (newLines !== undefined) {\n    hunk.newLines = newLines;\n  } else {\n    delete hunk.newLines;\n  }\n}\n\nfunction merge(mine, theirs, base) {\n  mine = loadPatch(mine, base);\n  theirs = loadPatch(theirs, base);\n  var ret = {}; // For index we just let it pass through as it doesn't have any necessary meaning.\n  // Leaving sanity checks on this to the API consumer that may know more about the\n  // meaning in their own context.\n\n  if (mine.index || theirs.index) {\n    ret.index = mine.index || theirs.index;\n  }\n\n  if (mine.newFileName || theirs.newFileName) {\n    if (!fileNameChanged(mine)) {\n      // No header or no change in ours, use theirs (and ours if theirs does not exist)\n      ret.oldFileName = theirs.oldFileName || mine.oldFileName;\n      ret.newFileName = theirs.newFileName || mine.newFileName;\n      ret.oldHeader = theirs.oldHeader || mine.oldHeader;\n      ret.newHeader = theirs.newHeader || mine.newHeader;\n    } else if (!fileNameChanged(theirs)) {\n      // No header or no change in theirs, use ours\n      ret.oldFileName = mine.oldFileName;\n      ret.newFileName = mine.newFileName;\n      ret.oldHeader = mine.oldHeader;\n      ret.newHeader = mine.newHeader;\n    } else {\n      // Both changed... figure it out\n      ret.oldFileName = selectField(ret, mine.oldFileName, theirs.oldFileName);\n      ret.newFileName = selectField(ret, mine.newFileName, theirs.newFileName);\n      ret.oldHeader = selectField(ret, mine.oldHeader, theirs.oldHeader);\n      ret.newHeader = selectField(ret, mine.newHeader, theirs.newHeader);\n    }\n  }\n\n  ret.hunks = [];\n  var mineIndex = 0,\n      theirsIndex = 0,\n      mineOffset = 0,\n      theirsOffset = 0;\n\n  while (mineIndex < mine.hunks.length || theirsIndex < theirs.hunks.length) {\n    var mineCurrent = mine.hunks[mineIndex] || {\n      oldStart: Infinity\n    },\n        theirsCurrent = theirs.hunks[theirsIndex] || {\n      oldStart: Infinity\n    };\n\n    if (hunkBefore(mineCurrent, theirsCurrent)) {\n      // This patch does not overlap with any of the others, yay.\n      ret.hunks.push(cloneHunk(mineCurrent, mineOffset));\n      mineIndex++;\n      theirsOffset += mineCurrent.newLines - mineCurrent.oldLines;\n    } else if (hunkBefore(theirsCurrent, mineCurrent)) {\n      // This patch does not overlap with any of the others, yay.\n      ret.hunks.push(cloneHunk(theirsCurrent, theirsOffset));\n      theirsIndex++;\n      mineOffset += theirsCurrent.newLines - theirsCurrent.oldLines;\n    } else {\n      // Overlap, merge as best we can\n      var mergedHunk = {\n        oldStart: Math.min(mineCurrent.oldStart, theirsCurrent.oldStart),\n        oldLines: 0,\n        newStart: Math.min(mineCurrent.newStart + mineOffset, theirsCurrent.oldStart + theirsOffset),\n        newLines: 0,\n        lines: []\n      };\n      mergeLines(mergedHunk, mineCurrent.oldStart, mineCurrent.lines, theirsCurrent.oldStart, theirsCurrent.lines);\n      theirsIndex++;\n      mineIndex++;\n      ret.hunks.push(mergedHunk);\n    }\n  }\n\n  return ret;\n}\n\nfunction loadPatch(param, base) {\n  if (typeof param === 'string') {\n    if (/^@@/m.test(param) || /^Index:/m.test(param)) {\n      return parsePatch(param)[0];\n    }\n\n    if (!base) {\n      throw new Error('Must provide a base reference or pass in a patch');\n    }\n\n    return structuredPatch(undefined, undefined, base, param);\n  }\n\n  return param;\n}\n\nfunction fileNameChanged(patch) {\n  return patch.newFileName && patch.newFileName !== patch.oldFileName;\n}\n\nfunction selectField(index, mine, theirs) {\n  if (mine === theirs) {\n    return mine;\n  } else {\n    index.conflict = true;\n    return {\n      mine: mine,\n      theirs: theirs\n    };\n  }\n}\n\nfunction hunkBefore(test, check) {\n  return test.oldStart < check.oldStart && test.oldStart + test.oldLines < check.oldStart;\n}\n\nfunction cloneHunk(hunk, offset) {\n  return {\n    oldStart: hunk.oldStart,\n    oldLines: hunk.oldLines,\n    newStart: hunk.newStart + offset,\n    newLines: hunk.newLines,\n    lines: hunk.lines\n  };\n}\n\nfunction mergeLines(hunk, mineOffset, mineLines, theirOffset, theirLines) {\n  // This will generally result in a conflicted hunk, but there are cases where the context\n  // is the only overlap where we can successfully merge the content here.\n  var mine = {\n    offset: mineOffset,\n    lines: mineLines,\n    index: 0\n  },\n      their = {\n    offset: theirOffset,\n    lines: theirLines,\n    index: 0\n  }; // Handle any leading content\n\n  insertLeading(hunk, mine, their);\n  insertLeading(hunk, their, mine); // Now in the overlap content. Scan through and select the best changes from each.\n\n  while (mine.index < mine.lines.length && their.index < their.lines.length) {\n    var mineCurrent = mine.lines[mine.index],\n        theirCurrent = their.lines[their.index];\n\n    if ((mineCurrent[0] === '-' || mineCurrent[0] === '+') && (theirCurrent[0] === '-' || theirCurrent[0] === '+')) {\n      // Both modified ...\n      mutualChange(hunk, mine, their);\n    } else if (mineCurrent[0] === '+' && theirCurrent[0] === ' ') {\n      var _hunk$lines; // Mine inserted\n\n\n      (_hunk$lines = hunk.lines).push.apply(_hunk$lines, _toConsumableArray(collectChange(mine)));\n    } else if (theirCurrent[0] === '+' && mineCurrent[0] === ' ') {\n      var _hunk$lines2; // Theirs inserted\n\n\n      (_hunk$lines2 = hunk.lines).push.apply(_hunk$lines2, _toConsumableArray(collectChange(their)));\n    } else if (mineCurrent[0] === '-' && theirCurrent[0] === ' ') {\n      // Mine removed or edited\n      removal(hunk, mine, their);\n    } else if (theirCurrent[0] === '-' && mineCurrent[0] === ' ') {\n      // Their removed or edited\n      removal(hunk, their, mine, true);\n    } else if (mineCurrent === theirCurrent) {\n      // Context identity\n      hunk.lines.push(mineCurrent);\n      mine.index++;\n      their.index++;\n    } else {\n      // Context mismatch\n      conflict(hunk, collectChange(mine), collectChange(their));\n    }\n  } // Now push anything that may be remaining\n\n\n  insertTrailing(hunk, mine);\n  insertTrailing(hunk, their);\n  calcLineCount(hunk);\n}\n\nfunction mutualChange(hunk, mine, their) {\n  var myChanges = collectChange(mine),\n      theirChanges = collectChange(their);\n\n  if (allRemoves(myChanges) && allRemoves(theirChanges)) {\n    // Special case for remove changes that are supersets of one another\n    if (arrayStartsWith(myChanges, theirChanges) && skipRemoveSuperset(their, myChanges, myChanges.length - theirChanges.length)) {\n      var _hunk$lines3;\n\n      (_hunk$lines3 = hunk.lines).push.apply(_hunk$lines3, _toConsumableArray(myChanges));\n\n      return;\n    } else if (arrayStartsWith(theirChanges, myChanges) && skipRemoveSuperset(mine, theirChanges, theirChanges.length - myChanges.length)) {\n      var _hunk$lines4;\n\n      (_hunk$lines4 = hunk.lines).push.apply(_hunk$lines4, _toConsumableArray(theirChanges));\n\n      return;\n    }\n  } else if (arrayEqual(myChanges, theirChanges)) {\n    var _hunk$lines5;\n\n    (_hunk$lines5 = hunk.lines).push.apply(_hunk$lines5, _toConsumableArray(myChanges));\n\n    return;\n  }\n\n  conflict(hunk, myChanges, theirChanges);\n}\n\nfunction removal(hunk, mine, their, swap) {\n  var myChanges = collectChange(mine),\n      theirChanges = collectContext(their, myChanges);\n\n  if (theirChanges.merged) {\n    var _hunk$lines6;\n\n    (_hunk$lines6 = hunk.lines).push.apply(_hunk$lines6, _toConsumableArray(theirChanges.merged));\n  } else {\n    conflict(hunk, swap ? theirChanges : myChanges, swap ? myChanges : theirChanges);\n  }\n}\n\nfunction conflict(hunk, mine, their) {\n  hunk.conflict = true;\n  hunk.lines.push({\n    conflict: true,\n    mine: mine,\n    theirs: their\n  });\n}\n\nfunction insertLeading(hunk, insert, their) {\n  while (insert.offset < their.offset && insert.index < insert.lines.length) {\n    var line = insert.lines[insert.index++];\n    hunk.lines.push(line);\n    insert.offset++;\n  }\n}\n\nfunction insertTrailing(hunk, insert) {\n  while (insert.index < insert.lines.length) {\n    var line = insert.lines[insert.index++];\n    hunk.lines.push(line);\n  }\n}\n\nfunction collectChange(state) {\n  var ret = [],\n      operation = state.lines[state.index][0];\n\n  while (state.index < state.lines.length) {\n    var line = state.lines[state.index]; // Group additions that are immediately after subtractions and treat them as one \"atomic\" modify change.\n\n    if (operation === '-' && line[0] === '+') {\n      operation = '+';\n    }\n\n    if (operation === line[0]) {\n      ret.push(line);\n      state.index++;\n    } else {\n      break;\n    }\n  }\n\n  return ret;\n}\n\nfunction collectContext(state, matchChanges) {\n  var changes = [],\n      merged = [],\n      matchIndex = 0,\n      contextChanges = false,\n      conflicted = false;\n\n  while (matchIndex < matchChanges.length && state.index < state.lines.length) {\n    var change = state.lines[state.index],\n        match = matchChanges[matchIndex]; // Once we've hit our add, then we are done\n\n    if (match[0] === '+') {\n      break;\n    }\n\n    contextChanges = contextChanges || change[0] !== ' ';\n    merged.push(match);\n    matchIndex++; // Consume any additions in the other block as a conflict to attempt\n    // to pull in the remaining context after this\n\n    if (change[0] === '+') {\n      conflicted = true;\n\n      while (change[0] === '+') {\n        changes.push(change);\n        change = state.lines[++state.index];\n      }\n    }\n\n    if (match.substr(1) === change.substr(1)) {\n      changes.push(change);\n      state.index++;\n    } else {\n      conflicted = true;\n    }\n  }\n\n  if ((matchChanges[matchIndex] || '')[0] === '+' && contextChanges) {\n    conflicted = true;\n  }\n\n  if (conflicted) {\n    return changes;\n  }\n\n  while (matchIndex < matchChanges.length) {\n    merged.push(matchChanges[matchIndex++]);\n  }\n\n  return {\n    merged: merged,\n    changes: changes\n  };\n}\n\nfunction allRemoves(changes) {\n  return changes.reduce(function (prev, change) {\n    return prev && change[0] === '-';\n  }, true);\n}\n\nfunction skipRemoveSuperset(state, removeChanges, delta) {\n  for (var i = 0; i < delta; i++) {\n    var changeContent = removeChanges[removeChanges.length - delta + i].substr(1);\n\n    if (state.lines[state.index + i] !== ' ' + changeContent) {\n      return false;\n    }\n  }\n\n  state.index += delta;\n  return true;\n}\n\nfunction calcOldNewLineCount(lines) {\n  var oldLines = 0;\n  var newLines = 0;\n  lines.forEach(function (line) {\n    if (typeof line !== 'string') {\n      var myCount = calcOldNewLineCount(line.mine);\n      var theirCount = calcOldNewLineCount(line.theirs);\n\n      if (oldLines !== undefined) {\n        if (myCount.oldLines === theirCount.oldLines) {\n          oldLines += myCount.oldLines;\n        } else {\n          oldLines = undefined;\n        }\n      }\n\n      if (newLines !== undefined) {\n        if (myCount.newLines === theirCount.newLines) {\n          newLines += myCount.newLines;\n        } else {\n          newLines = undefined;\n        }\n      }\n    } else {\n      if (newLines !== undefined && (line[0] === '+' || line[0] === ' ')) {\n        newLines++;\n      }\n\n      if (oldLines !== undefined && (line[0] === '-' || line[0] === ' ')) {\n        oldLines++;\n      }\n    }\n  });\n  return {\n    oldLines: oldLines,\n    newLines: newLines\n  };\n} // See: http://code.google.com/p/google-diff-match-patch/wiki/API\n\n\nfunction convertChangesToDMP(changes) {\n  var ret = [],\n      change,\n      operation;\n\n  for (var i = 0; i < changes.length; i++) {\n    change = changes[i];\n\n    if (change.added) {\n      operation = 1;\n    } else if (change.removed) {\n      operation = -1;\n    } else {\n      operation = 0;\n    }\n\n    ret.push([operation, change.value]);\n  }\n\n  return ret;\n}\n\nfunction convertChangesToXML(changes) {\n  var ret = [];\n\n  for (var i = 0; i < changes.length; i++) {\n    var change = changes[i];\n\n    if (change.added) {\n      ret.push('<ins>');\n    } else if (change.removed) {\n      ret.push('<del>');\n    }\n\n    ret.push(escapeHTML(change.value));\n\n    if (change.added) {\n      ret.push('</ins>');\n    } else if (change.removed) {\n      ret.push('</del>');\n    }\n  }\n\n  return ret.join('');\n}\n\nfunction escapeHTML(s) {\n  var n = s;\n  n = n.replace(/&/g, '&amp;');\n  n = n.replace(/</g, '&lt;');\n  n = n.replace(/>/g, '&gt;');\n  n = n.replace(/\"/g, '&quot;');\n  return n;\n}\n\nexport { Diff, applyPatch, applyPatches, canonicalize, convertChangesToDMP, convertChangesToXML, createPatch, createTwoFilesPatch, diffArrays, diffChars, diffCss, diffJson, diffLines, diffSentences, diffTrimmedLines, diffWords, diffWordsWithSpace, merge, parsePatch, structuredPatch };","export type DeepRequired<T> = {\n\t[P in keyof T]-?: DeepRequired<T[P]>;\n};\n\nexport type DeepReadonly<T> = {\n\treadonly [P in keyof T]: DeepReadonly<T[P]>;\n};\n\nexport type Result<O, E> = ResultOk<O> | ResultError<E>;\nexport interface ResultOk<O> {\n\treadonly type: \"Ok\";\n\treadonly value: O;\n}\nexport interface ResultError<E> {\n\treadonly type: \"Error\";\n\treadonly error: E;\n}\n\nexport function lazy<T>(supplier: () => NonNullable<T>): () => T {\n\tlet value: T | undefined = undefined;\n\treturn () => {\n\t\tif (value === undefined) {\n\t\t\tvalue = supplier();\n\t\t}\n\t\treturn value;\n\t};\n}\n\nexport function delay(ms: number): Promise<void> {\n\treturn new Promise(resolve => {\n\t\tsetTimeout(() => resolve(), ms);\n\t});\n}\n\nexport function firstOf<T>(iter: Iterable<T>): T | undefined {\n\tfor (const item of iter) {\n\t\treturn item;\n\t}\n\treturn undefined;\n}\n\nexport interface CategoryGroup<T, G> {\n\tcategory: G;\n\titems: T[];\n}\nexport function groupByCategory<T, G>(\n\titer: Iterable<T>,\n\tcategorize: (item: T, index: number) => G\n): CategoryGroup<T, G>[] {\n\tconst result: CategoryGroup<T, G>[] = [];\n\n\tlet index = 0;\n\tfor (const item of iter) {\n\t\tconst category = categorize(item, index++);\n\n\t\tconst last = result[result.length - 1] as CategoryGroup<T, G> | undefined;\n\t\tif (last && last.category === category) {\n\t\t\tlast.items.push(item);\n\t\t} else {\n\t\t\tresult.push({ category, items: [item] });\n\t\t}\n\t}\n\n\treturn result;\n}\n\nexport type Comparator<A, B = A> = (a: A, b: B) => boolean;\n\nexport function endsWith<A, B>(sequence: readonly A[], needle: readonly B[], comparator?: Comparator<A, B>): boolean {\n\tif (needle.length > sequence.length) {\n\t\treturn false;\n\t}\n\n\tconst start = sequence.length - needle.length;\n\tif (comparator) {\n\t\tfor (let j = 0; j < needle.length; j++) {\n\t\t\tif (!comparator(sequence[start + j], needle[j])) {\n\t\t\t\treturn false;\n\t\t\t}\n\t\t}\n\t} else {\n\t\tfor (let j = 0; j < needle.length; j++) {\n\t\t\tif ((sequence[start + j] as unknown) !== needle[j]) {\n\t\t\t\treturn false;\n\t\t\t}\n\t\t}\n\t}\n\treturn true;\n}\n\nexport function shorten(text: string, maxLength: number): string {\n\tif (text.length <= maxLength) {\n\t\treturn text;\n\t} else {\n\t\tconst chars = [...text];\n\t\tif (chars.length <= maxLength) {\n\t\t\treturn text;\n\t\t}\n\t\treturn chars.slice(0, maxLength).join(\"\") + \"…\";\n\t}\n}\nexport function shortenWords(text: string, minLength: number, maxLength: number): string {\n\tif (text.length <= maxLength) {\n\t\treturn text;\n\t} else {\n\t\tconst chars = [...text];\n\t\tif (chars.length <= maxLength) {\n\t\t\treturn text;\n\t\t}\n\n\t\tlet lastSpace = maxLength;\n\t\tconst space = /^\\s$/;\n\t\tfor (let i = maxLength - 1; i >= minLength; i--) {\n\t\t\tif (space.test(chars[i])) {\n\t\t\t\tlastSpace = i;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\treturn chars.slice(0, lastSpace).join(\"\").trim() + \"…\";\n\t}\n}\n\nexport function debugAssert(condition: boolean, message?: string): asserts condition {\n\tif (!condition) {\n\t\tthrow new Error(message);\n\t}\n}\n\nexport function assertNever(value: never): never {\n\tthrow new Error(`Unexpected value: ${value}`);\n}\n\nexport function noop(): void {\n\t// noop\n}\n\nexport function identity<T>(value: T): T {\n\treturn value;\n}\n\nexport function isValidUrl(url: string): boolean {\n\ttry {\n\t\tnew URL(url);\n\t\treturn true;\n\t} catch (e) {\n\t\treturn false;\n\t}\n}\n\nexport const EMPTY_ARRAY: readonly never[] = [];\nexport const EMPTY_SET: ReadonlySet<never> = new Set();\nexport const EMPTY_MAP: ReadonlyMap<never, never> = new Map<never, never>();\n\nexport type TypeVariant = { readonly type: string };\nexport type TypeVisitor<V extends TypeVariant, R> = {\n\t[K in V[\"type\"]]: V extends { readonly type: K } ? (value: V) => R : never;\n};\nexport function visitType<V extends TypeVariant, R>(value: V, visitor: TypeVisitor<V, R>): R {\n\tconst fn = visitor[value.type as never] as (value: V) => R;\n\treturn fn(value);\n}\n","import { diffArrays } from \"diff\";\nimport { Comparator, endsWith } from \"./util\";\n\n/**\n * A edit is an operation that transforms parts of the *left* token stream A into the *right* token stream B.\n */\nexport type Edit<A, B = A> = Unchanged<A, B> | Changed<A, B>;\n\nexport interface Unchanged<A, B = A> {\n\treadonly type: \"Unchanged\";\n\tleft: A[];\n\tright: B[];\n}\nexport interface Changed<A, B = A> {\n\treadonly type: \"Changed\";\n\tremoved: A[];\n\tadded: B[];\n}\n\nexport type EditPair<A, B = A> = [Unchanged<A, B>, Changed<A, B>];\n\nfunction merge<A, B>(edits: Iterable<Edit<A, B>>): Edit<A, B>[] {\n\tconst result: Edit<A, B>[] = [{ type: \"Unchanged\", left: [], right: [] }];\n\n\tfor (const edit of edits) {\n\t\tconst last = result[result.length - 1];\n\n\t\tif (last.type === \"Unchanged\" && edit.type === \"Unchanged\") {\n\t\t\t// append to the last change\n\t\t\tlast.left.push(...edit.left);\n\t\t\tlast.right.push(...edit.right);\n\t\t} else if (last.type === \"Changed\" && edit.type === \"Changed\") {\n\t\t\t// append to the last change\n\t\t\tlast.removed.push(...edit.removed);\n\t\t\tlast.added.push(...edit.added);\n\t\t} else {\n\t\t\tresult.push(edit);\n\t\t}\n\t}\n\n\treturn result;\n}\n\nexport function fromDiff<A>(left: readonly A[], right: readonly A[], comparator: Comparator<A>): Iterable<Edit<A>> {\n\treturn minimize(fromRawDiff(left, right, comparator), comparator, comparator);\n}\n\nfunction* fromRawDiff<A, B>(\n\tleft: readonly A[],\n\tright: readonly B[],\n\tcomparator: Comparator<A, B>\n): Iterable<Edit<A, B>> {\n\tconst diff = diffArrays(left as A[], right as B[], { comparator });\n\n\tlet leftTokenIndex = 0;\n\tlet rightTokenIndex = 0;\n\n\tfor (const change of diff) {\n\t\tif (change.added) {\n\t\t\trightTokenIndex += change.value.length;\n\n\t\t\tyield {\n\t\t\t\ttype: \"Changed\",\n\t\t\t\tremoved: [],\n\t\t\t\tadded: change.value as B[],\n\t\t\t};\n\t\t} else if (change.removed) {\n\t\t\tleftTokenIndex += change.value.length;\n\n\t\t\tyield {\n\t\t\t\ttype: \"Changed\",\n\t\t\t\tremoved: change.value as A[],\n\t\t\t\tadded: [],\n\t\t\t};\n\t\t} else {\n\t\t\tconst length = change.value.length;\n\t\t\tconst leftValue = left.slice(leftTokenIndex, leftTokenIndex + length);\n\t\t\tconst rightValue = right.slice(rightTokenIndex, rightTokenIndex + length);\n\t\t\tleftTokenIndex += length;\n\t\t\trightTokenIndex += length;\n\n\t\t\tyield {\n\t\t\t\ttype: \"Unchanged\",\n\t\t\t\tleft: leftValue,\n\t\t\t\tright: rightValue,\n\t\t\t};\n\t\t}\n\t}\n}\n\n/**\n * The diff algorithm sometimes returns results like this:\n *\n * ```diff\n * - [the] new color of the\n * + [the]\n * ```\n *\n * Where both `[the]` tokens are the unchanged tokens.\n *\n * We can minimize the number of changes by trying to move the list of unchanged tokens to the back. Example\n *\n * ```diff\n * - the new color of [the]\n * + [the]\n * ```\n */\nfunction minimize<A, B>(\n\tedits: Iterable<Edit<A, B>>,\n\tcomparatorA: Comparator<A>,\n\tcomparatorB: Comparator<B>\n): Iterable<Edit<A, B>> {\n\tconst result: Edit<A, B>[] = merge(edits);\n\n\tfor (let i = 0; i < result.length; i += 2) {\n\t\tconst unchanged = result[i] as Unchanged<A, B>;\n\t\tconst changed = result[i + 1] as Changed<A, B> | undefined;\n\t\tif (!changed) {\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (changed.added.length === 0) {\n\t\t\tif (endsWith(changed.removed, unchanged.left, comparatorA)) {\n\t\t\t\tconst splitPoint = changed.removed.length - unchanged.left.length;\n\t\t\t\tconst before = changed.removed.slice(0, splitPoint);\n\t\t\t\tconst after = changed.removed.slice(splitPoint);\n\t\t\t\tresult[i] = {\n\t\t\t\t\ttype: \"Changed\",\n\t\t\t\t\tremoved: [...unchanged.left, ...before],\n\t\t\t\t\tadded: [],\n\t\t\t\t};\n\t\t\t\tresult[i + 1] = {\n\t\t\t\t\ttype: \"Unchanged\",\n\t\t\t\t\tleft: after,\n\t\t\t\t\tright: unchanged.right,\n\t\t\t\t};\n\t\t\t}\n\t\t} else if (changed.removed.length === 0) {\n\t\t\tif (endsWith(changed.added, unchanged.right, comparatorB)) {\n\t\t\t\tconst splitPoint = changed.added.length - unchanged.right.length;\n\t\t\t\tconst before = changed.added.slice(0, splitPoint);\n\t\t\t\tconst after = changed.added.slice(splitPoint);\n\t\t\t\tresult[i] = {\n\t\t\t\t\ttype: \"Changed\",\n\t\t\t\t\tremoved: [],\n\t\t\t\t\tadded: [...unchanged.right, ...before],\n\t\t\t\t};\n\t\t\t\tresult[i + 1] = {\n\t\t\t\t\ttype: \"Unchanged\",\n\t\t\t\t\tleft: unchanged.left,\n\t\t\t\t\tright: after,\n\t\t\t\t};\n\t\t\t}\n\t\t}\n\t}\n\n\treturn result;\n}\n\nexport function* iteratePairs<A, B>(edits: Iterable<Edit<A, B>>): Iterable<EditPair<A, B>> {\n\tconst merged = merge(edits);\n\n\t// We know that the items in changes always start with Unchanged alternate between Unchanged and Changed\n\tfor (let i = 0; i < merged.length; i += 2) {\n\t\tconst unchanged = merged[i] as Unchanged<A, B>;\n\t\tconst changed = (merged[i + 1] as Changed<A, B> | undefined) ?? {\n\t\t\ttype: \"Changed\",\n\t\t\tadded: [],\n\t\t\tremoved: [],\n\t\t};\n\n\t\tyield [unchanged, changed];\n\t}\n}\n\nexport function* filterUnchanged<A, B>(\n\tedits: Iterable<Edit<A, B>>,\n\tcondition: (edit: Unchanged<A, B>) => boolean\n): Iterable<Edit<A, B>> {\n\tfor (const change of merge(edits)) {\n\t\tif (change.type === \"Unchanged\" && !condition(change)) {\n\t\t\tyield {\n\t\t\t\ttype: \"Changed\",\n\t\t\t\tremoved: change.left,\n\t\t\t\tadded: change.right,\n\t\t\t};\n\t\t} else {\n\t\t\tyield change;\n\t\t}\n\t}\n}\n","import { EditPair, filterUnchanged, fromDiff, iteratePairs } from \"./edit\";\nimport { debugAssert, DeepReadonly, groupByCategory } from \"./util\";\n\nexport interface SimpleCombinedDiff {\n\treadonly diff: DeepReadonly<CombinedChange<string>>[];\n\treadonly sharedWords: number;\n}\nexport function getSimpleCombinedDiff(left: string, right: string): SimpleCombinedDiff {\n\tconst { diff } = getCombinedDiff(left, right);\n\n\tconst sharedWords = diff.reduce((acc, change) => acc + change.left.equal.length, 0);\n\n\treturn {\n\t\tdiff: diff.map(c => {\n\t\t\treturn new CombinedChange<string>(\n\t\t\t\t{ equal: join(c.left.equal), removed: join(c.left.removed) },\n\t\t\t\t{ equal: join(c.right.equal), added: join(c.right.added) }\n\t\t\t);\n\t\t}),\n\t\tsharedWords,\n\t};\n}\nfunction join(words: readonly WordToken[]): string {\n\treturn words.join(\"\");\n}\n\nexport interface LeftChange<T> {\n\tequal: T;\n\tremoved: T;\n}\nexport interface RightChange<T> {\n\tequal: T;\n\tadded: T;\n}\nexport class CombinedChange<T> {\n\treadonly left: LeftChange<T>;\n\treadonly right: RightChange<T>;\n\n\tconstructor(left: LeftChange<T>, right: RightChange<T>) {\n\t\tthis.left = left;\n\t\tthis.right = right;\n\t}\n\n\tstatic fromEditPair<T>([unchanged, changed]: EditPair<T>): CombinedChange<T[]> {\n\t\treturn new CombinedChange<T[]>(\n\t\t\t{ equal: unchanged.left, removed: changed.removed },\n\t\t\t{ equal: unchanged.right, added: changed.added }\n\t\t);\n\t}\n}\n\nexport function getCombinedDiff(\n\tleft: string,\n\tright: string\n): { diff: CombinedChange<WordToken[]>[]; scores: Map<WordToken, number> } {\n\tlet edits = fromDiff(tokenizeWords(left), tokenizeWords(right), WordToken.equals);\n\n\tconst filteredOut = new Map<WordToken, WordToken>();\n\n\t// filter\n\tedits = filterUnchanged(edits, e => {\n\t\tconst ignore = ignoreUnchanged(e.left.join(\"\")) || ignoreUnchanged(e.right.join(\"\"));\n\t\tif (ignore) {\n\t\t\tdebugAssert(e.left.length === e.right.length);\n\n\t\t\t// both left and right contain the same number of tokens\n\t\t\tfor (let i = 0; i < e.left.length; i++) {\n\t\t\t\tconst l = e.left[i];\n\t\t\t\tconst r = e.right[i];\n\n\t\t\t\tdebugAssert(!filteredOut.has(l));\n\t\t\t\tfilteredOut.set(l, r);\n\t\t\t\tdebugAssert(!filteredOut.has(r));\n\t\t\t\tfilteredOut.set(r, l);\n\t\t\t}\n\t\t}\n\t\treturn !ignore;\n\t});\n\n\t// diff\n\tconst diff = [...iteratePairs(edits)].map(CombinedChange.fromEditPair);\n\n\t// score the filtered-out tokens\n\tconst scores = new Map<WordToken, number>();\n\tconst increaseScore = (token: WordToken, amount: number): void => {\n\t\tconst other = filteredOut.get(token);\n\t\tdebugAssert(other !== undefined);\n\n\t\tscores.set(token, Math.max(scores.get(token) ?? 0, amount));\n\t\tscores.set(other, Math.max(scores.get(other) ?? 0, amount));\n\t};\n\tdiff.flatMap(c => [c.left.removed, c.right.added])\n\t\t.flatMap(seq => groupByCategory(seq, t => filteredOut.has(t)))\n\t\t.filter(g => g.category)\n\t\t.forEach(g => {\n\t\t\tconst groupScore = g.items.join(\"\").length;\n\t\t\tg.items.forEach(t => increaseScore(t, groupScore));\n\t\t});\n\n\treturn { diff, scores };\n}\n\n/**\n * Some unchanged section are too small to be useful. This includes spaces, punctuation, and stop words.\n *\n * This function decides whether an unchanged section will be ignore and combined with whatever change surrounds it.\n */\nfunction ignoreUnchanged(value: string): boolean {\n\t//return false;\n\treturn (\n\t\t// only spaces and/or punctuation\n\t\t/^[\\s\\p{P}]*$/u.test(value) ||\n\t\t// too short\n\t\tvalue.length <= 12\n\t);\n}\n\nexport class WordToken {\n\treadonly raw: string;\n\treadonly compareValue: string;\n\n\tconstructor(raw: string, compareValue: string) {\n\t\tthis.raw = raw;\n\t\tthis.compareValue = compareValue;\n\t}\n\n\ttoString(): string {\n\t\treturn this.raw;\n\t}\n\n\tstatic equals(a: WordToken, b: WordToken): boolean {\n\t\treturn a.compareValue === b.compareValue;\n\t}\n}\n\nconst NON_WORD_CHAR = /[\\s()[\\]{},;:]/.source;\nconst WORD_CHAR = NON_WORD_CHAR.replace(/^\\[/, \"[^\");\nconst WORD_TOKEN_REGEX = `${NON_WORD_CHAR}*(${WORD_CHAR}+)${NON_WORD_CHAR}*`;\n\nfunction tokenizeWords(text: string): WordToken[] {\n\tconst tokens: WordToken[] = [];\n\n\tlet last = 0;\n\tconst word = RegExp(WORD_TOKEN_REGEX, \"uy\");\n\tfor (let m; (m = word.exec(text)); ) {\n\t\tconst raw = m[0];\n\t\tconst compareValue = m[1].replace(/[^\\p{Alpha}\\p{digit}]+/gu, \"\").toUpperCase() || m[1];\n\n\t\ttokens.push(new WordToken(raw, compareValue));\n\t\tlast = m.index + raw.length;\n\t}\n\n\tif (last < text.length) {\n\t\tconst raw = text.slice(last);\n\t\ttokens.push(new WordToken(raw, raw));\n\t}\n\n\treturn tokens;\n}\n","import { getSimpleCombinedDiff } from \"./alignment\";\n\nself.onmessage = ({ data: { left, right, id } }) => {\n\tconst diff = getSimpleCombinedDiff(left, right);\n\tself.postMessage({ diff, id });\n};\n"],"names":["Diff","buildValues","diff","components","newString","oldString","useLongestToken","componentPos","componentLen","length","newPos","oldPos","component","removed","value","join","slice","count","added","tmp","map","i","oldValue","lastComponent","equals","pop","clonePath","path","prototype","options","arguments","undefined","callback","this","self","done","setTimeout","castInput","removeEmpty","tokenize","newLen","oldLen","editLength","maxEditLength","bestPath","extractCommon","execEditLength","diagonalPath","basePath","addPath","removePath","_oldPos","canAdd","canRemove","pushComponent","exec","ret","last","push","commonCount","left","right","comparator","ignoreCase","toLowerCase","array","split","chars","extendedWordChars","reWhitespace","wordDiff","ignoreWhitespace","test","tokens","splice","lineDiff","retLines","linesAndNewlines","line","newlineIsToken","trim","sentenceDiff","cssDiff","_typeof","obj","Symbol","iterator","constructor","objectPrototypeToString","Object","toString","jsonDiff","canonicalize","stack","replacementStack","replacer","key","canonicalizedObj","call","Array","toJSON","_key","sortedKeys","hasOwnProperty","sort","_this$options","undefinedReplacement","_this$options$stringi","stringifyReplacer","k","v","JSON","stringify","replace","arrayDiff","endsWith","sequence","needle","start","j","debugAssert","condition","message","Error","Set","Map","merge","edits","result","type","edit","fromDiff","comparatorA","comparatorB","unchanged","changed","splitPoint","before","after","minimize","oldArr","newArr","leftTokenIndex","rightTokenIndex","change","leftValue","rightValue","fromRawDiff","iteratePairs","merged","getSimpleCombinedDiff","tokenizeWords","WordToken","filteredOut","filterUnchanged","e","ignore","ignoreUnchanged","l","r","has","set","CombinedChange","fromEditPair","scores","increaseScore","token","amount","other","get","Math","max","flatMap","c","seq","iter","categorize","index","item","category","items","groupByCategory","t","filter","g","forEach","groupScore","getCombinedDiff","sharedWords","reduce","acc","equal","words","raw","compareValue","a","b","NON_WORD_CHAR","source","WORD_CHAR","WORD_TOKEN_REGEX","text","word","RegExp","m","toUpperCase","onmessage","data","id","postMessage"],"sourceRoot":""}